{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from utilities import model_creation, metrics_and_plots, data_processing\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "# Let's see our luck\n",
    "print(\"We are running {} version of the TensorFlow,\\nand we have {} GPUs Available.\".format(\n",
    "    tf.__version__, len(tf.config.list_physical_devices('GPU'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    tf.keras.metrics.SpecificityAtSensitivity(sensitivity=0.5, name = 'Specificity'),\n",
    "    tf.keras.metrics.SensitivityAtSpecificity(specificity=0.5, name = 'Sensitivity')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ca46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"../../Dataset/2_0_1_splitted\")\n",
    "os.chdir(\"../../Dataset/1_asli_splitted\")\n",
    "\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "val_dir = \"validation\"\n",
    "\n",
    "\n",
    "train_iterator = data_processing.generate_iterator(path=train_dir, augmentation = True, \n",
    "                                                   rescale = 0, batch_size = batch_size)\n",
    "test_iterator = data_processing.generate_iterator(path=test_dir, augmentation=False, \n",
    "                                                  shuffle=False, rescale=0, batch_size = batch_size)\n",
    "validation_iterator = data_processing.generate_iterator(path=val_dir, augmentation=False, \n",
    "                                                        shuffle=False, rescale=0, batch_size = batch_size)\n",
    "\n",
    "# data_processing.display_images(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c88825",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_hybrid_model = True\n",
    "is_hybrid_model_main_only = False\n",
    "\n",
    "is_test_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71889dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the callbacks to save the model and reduce the learning rate\n",
    "import os\n",
    "\n",
    "## FOR ENHANCED DATASET\n",
    "save_dir_for_enhanced = os.path.join('..', '..', \"Result\", '2_4_reference_updated')\n",
    "if is_hybrid_model:\n",
    "    if is_hybrid_model_main_only:\n",
    "        model_name_for_enhanced = 'hybrid_model_main_only'\n",
    "    else:\n",
    "        model_name_for_enhanced = 'hybrid_model'\n",
    "else:\n",
    "    architecture = \"VGG16\"\n",
    "    model_name_for_enhanced = f'from_tensorflow_{architecture}'\n",
    "if not os.path.isdir(save_dir_for_enhanced):\n",
    "    os.makedirs(save_dir_for_enhanced)\n",
    "filepath_for_enhanced = os.path.join(save_dir_for_enhanced, f\"{model_name_for_enhanced}.h5\")\n",
    "csv_for_enhanced = os.path.join(save_dir_for_enhanced, f\"{model_name_for_enhanced}.csv\")\n",
    "\n",
    "# prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint_for_enhanced = ModelCheckpoint(filepath=filepath_for_enhanced,\n",
    "                                          monitor= 'val_Specificity',\n",
    "                                          verbose=1,\n",
    "                                          save_best_only=True,\n",
    "                                          save_weights_only=True,\n",
    "                                          mode='max')\n",
    "\n",
    "\n",
    "CSVLogger_for_enhanced = CSVLogger(filename=csv_for_enhanced, separator=',',\n",
    "                                  append=False)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=0.5,\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=1e-6,\n",
    "                               monitor='val_Specificity',\n",
    "                               mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(patience=6,\n",
    "                               monitor='val_Specificity',\n",
    "                               start_from_epoch=6,\n",
    "                               verbose=1,\n",
    "                               mode='max')\n",
    "\n",
    "\n",
    "callbacks_for_enhanced = [checkpoint_for_enhanced, lr_reducer, CSVLogger_for_enhanced, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_hybrid_model:\n",
    "    if is_hybrid_model_main_only:\n",
    "        model = model_creation.main_model_only(input_shape=input_shape, num_classes=5, blocks=4)\n",
    "    else:\n",
    "        model = model_creation.final_model(input_shape=input_shape, num_classes=5, blocks=4)\n",
    "else:\n",
    "    model = model_creation.model_from_tf(input_shape=input_shape, num_classes=5, is_transfer_learning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                           loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "                           metrics = METRICS)\n",
    "# plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15251f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not is_test_only:\n",
    "    history = model.fit(x=train_iterator, epochs=epochs, \n",
    "                        validation_data=validation_iterator, \n",
    "                        callbacks=callbacks_for_enhanced,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_test_only:\n",
    "    import numpy as np\n",
    "    np.save('history.npy', history.history)\n",
    "    # In order to load, we will use the following line\n",
    "    # history1 = np.load('history.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_test_only:\n",
    "    metrics_and_plots.plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448254a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath_for_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_baseline = model.predict(test_iterator, batch_size=64)\n",
    "y_test = to_categorical(test_iterator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(test_iterator,\n",
    "                                  batch_size=64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print('.......................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "\n",
    "y_score = test_predictions_baseline\n",
    "n_classes = 5\n",
    "metrics_and_plots.plot_roc(y_test, y_score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_by_category(predict_categorical):\n",
    "    for result in predict_categorical:\n",
    "        yield tf.math.argmax(result).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = list(predict_label_by_category(y_test))\n",
    "predict_label = list(predict_label_by_category(y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588da70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 score - micro: {f1_score(test_label, predict_label, average='micro')}\\nF1 score - macro: {f1_score(test_label, predict_label, average='macro')}\\nF1 score - weighted: {f1_score(test_label, predict_label, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e8fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
